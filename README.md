# ğŸ“¦ Banggood Product Data Pipeline & Analysis

### *Data Engineering Hackathon -- Batch 3*

This project is a complete end-to-end data engineering pipeline built
for analyzing product trends on **Banggood.com** across five different
categories.\
It includes **web scraping**, **data cleaning**, **exploratory data
analysis (EDA)**, **SQL Server ingestion**, **SQL analytics**, and a
**final report with insights**.

## ğŸ“‘ Table of Contents

-   [Overview](#overview)
-   [Features](#features)
-   [Project Architecture](#project-architecture)
-   [Tech Stack](#tech-stack)
-   [Folder Structure](#folder-structure)
-   [Pipeline Steps](#pipeline-steps)
    -   [1. Web Scraping](#1ï¸âƒ£-web-scraping)
    -   [2. Data Cleaning &
        Transformation](#2ï¸âƒ£-data-cleaning--transformation)
    -   [3. Exploratory Data Analysis
        (Python)](#3ï¸âƒ£-exploratory-data-analysis-python)
    -   [4. SQL Server Ingestion](#4ï¸âƒ£-sql-server-ingestion)
    -   [5. SQL Aggregated Queries](#5ï¸âƒ£-sql-aggregated-queries)
-   [How to Run](#how-to-run)
-   [Outputs](#outputs)
-   [Conclusion](#conclusion)

## ğŸ“Œ Overview

The goal of this project is to simulate a real-world data engineering
workflow where product information from Banggood is extracted, cleaned,
analyzed, stored in SQL Server, and later used for aggregated insights.

## â­ Features

âœ” Scrapes selected categories with pagination\
âœ” Cleans and transforms raw data\
âœ” Creates derived features\
âœ” Generates multiple EDA visualizations\
âœ” Loads data into SQL Server\
âœ” Runs SQL aggregated analytics\
âœ” Produces final report and recommendations

## ğŸ— Project Architecture

    [ Web Scraping ]
            â†“
    [ Raw Data (.csv) ]
            â†“
    [ Cleaning & Transformation (Pandas) ]
            â†“
    [ Processed Data ]
            â†“
    [ SQL Server Storage ]
            â†“
    [ SQL Aggregate Analysis ]
            â†“
    [ Final Report + Visualizations ]

## ğŸ›  Tech Stack

  Component         Tools Used
  ----------------- -----------------------------------
  Language          Python 3
  Scraping          requests, BeautifulSoup, Selenium
  Data Processing   Pandas, NumPy
  Visualization     Matplotlib, Seaborn
  Database          SQL Server
  Connectivity      pyodbc
  Reporting         Markdown / Jupyter Notebook

## ğŸ“ Folder Structure

    project/
    â”‚â”€â”€ scrapers/
    â”‚â”€â”€ data/raw/
    â”‚â”€â”€ data/processed/
    â”‚â”€â”€ sql/
    â”‚â”€â”€ analysis/
    â”‚â”€â”€ images/
    â””â”€â”€ README.md

## ğŸš€ Pipeline Steps

### **1ï¸âƒ£ Web Scraping**

-   Scraped **5 categories** with pagination\
-   Extracted: name, price, rating, reviews, URL\
-   Saved raw CSVs in `data/raw/`

### **2ï¸âƒ£ Data Cleaning & Transformation**

-   Cleaned numeric formats\
-   Handled missing values\
-   Removed duplicates\
-   Created derived features such as value_score, price_per_review

### **3ï¸âƒ£ Exploratory Data Analysis (Python)**

Performed 5+ analyses:\
- Price distribution\
- Rating distribution\
- Price vs Rating correlation\
- Top reviewed products\
- Best value items

### **4ï¸âƒ£ SQL Server Ingestion**

-   Created database schema\
-   Loaded cleaned CSVs\
-   Validated row counts

### **5ï¸âƒ£ SQL Aggregated Queries**

Queries include:\
- Avg price per category\
- Avg rating per category\
- Top reviewed items\
- Product count\
- Best value items

## â–¶ï¸ How to Run

    uv pip install -r requirements.txt  
    uv run scrapers/main_scraper.py  
    python cleaning_script.py  
    python sql/load_to_sql.py  

## ğŸ“Š Outputs

âœ” Clean CSVs\
âœ” Visual graphs\
âœ” SQL insights\
âœ” Final report

## ğŸ§  Conclusion

This project demonstrates a complete data engineering workflow from
scraping to SQL analytics, showcasing strong Python, SQL, and data
engineering skills.
